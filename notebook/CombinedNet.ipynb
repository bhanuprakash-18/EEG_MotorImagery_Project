{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31b6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import mne\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\n",
    "from functools import partial\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from ray import tune\n",
    "from ray import train\n",
    "from ray.train import Checkpoint, get_checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray.cloudpickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a327f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard channel sets\n",
    "CHANNELS_64 = None  # use all\n",
    "CHANNELS_38 = list(range(38))\n",
    "CHANNELS_19 = [\"Fp1\",\"Fp2\",\"F3\",\"F4\",\"C3\",\"C4\",\"P3\",\"P4\",\"O1\",\"O2\",\n",
    "                \"F7\",\"F8\",\"T3\",\"T4\",\"T5\",\"T6\",\"Fz\",\"Cz\",\"Pz\"]\n",
    "CHANNELS_8 = [\"F3\",\"F4\",\"C3\",\"C4\",\"Cz\",\"P3\",\"P4\",\"Pz\"]\n",
    "\n",
    "def pick_channels(raw, n_channels=64):\n",
    "    if n_channels == 64 or n_channels is None:\n",
    "        return raw\n",
    "    elif n_channels == 38:\n",
    "        return raw.copy().pick_channels([raw.ch_names[i] for i in CHANNELS_38])\n",
    "    elif n_channels == 19:\n",
    "        return raw.copy().pick_channels(CHANNELS_19)\n",
    "    elif n_channels == 8:\n",
    "        return raw.copy().pick_channels(CHANNELS_8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0ba6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path, T=4, n_channels=64, ds=1):\n",
    "    \"\"\"\n",
    "    Processes one EDF file: filtering, referencing, epoching, removing T0, normalization\n",
    "    \"\"\"\n",
    "    raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "    \n",
    "    # Bandpass filter 4-40 Hz\n",
    "    raw.filter(4., 40., fir_design='firwin')\n",
    "    \n",
    "    # Common average reference\n",
    "    raw.set_eeg_reference(\"average\")\n",
    "    \n",
    "    # Channel selection\n",
    "    raw = pick_channels(raw, n_channels)\n",
    "    \n",
    "    # Convert annotations to events\n",
    "    event_id = {'T0':0, 'T1':1, 'T2':2}\n",
    "    events, _ = mne.events_from_annotations(raw, event_id=event_id)\n",
    "    \n",
    "    # Epoching\n",
    "    epochs = mne.Epochs(\n",
    "        raw, events, event_id=event_id,\n",
    "        tmin=0, tmax=T,\n",
    "        baseline=None,\n",
    "        preload=True\n",
    "    )\n",
    "    \n",
    "    X = epochs.get_data()  # shape: trials × channels × samples\n",
    "    y = epochs.events[:, -1]  # labels\n",
    "    \n",
    "    # Remove T0 (idle) for left vs right classification\n",
    "    mask = y != 0\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    y = y - 1  # relabel: T1 -> 0, T2 -> 1\n",
    "    \n",
    "    # Downsampling\n",
    "    if ds > 1:\n",
    "        X = X[:, :, ::ds]\n",
    "    \n",
    "    # Normalize per trial\n",
    "    for i in range(len(X)):\n",
    "        X[i] = (X[i] - X[i].mean(axis=-1, keepdims=True)) / (X[i].std(axis=-1, keepdims=True)+1e-6)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922ec00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 EDF files\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob(\"../data/full_data/S*/S*R*.edf\")\n",
    "all_files = all_files[:30]  # limit to first 30 files for quicker testing\n",
    "print(f\"Found {len(all_files)} EDF files\")\n",
    "\n",
    "X_list, y_list = [], []\n",
    "target_T = None\n",
    "skipped_files = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eabf077d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S109/S109R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Set target_T = 641 from file ../data/full_data/S109/S109R08.edf\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S109/S109R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S109/S109R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S079/S079R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S079/S079R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S079/S079R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S105/S105R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S105/S105R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S105/S105R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S037/S037R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "1 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S037/S037R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "1 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S037/S037R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19839  =      0.000 ...   123.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S095/S095R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S095/S095R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S095/S095R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S100/S100R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 15743  =      0.000 ...   122.992 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 213 samples (1.664 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "24 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 24 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Skipping file ../data/full_data/S100/S100R08.edf because n_times=513 < target_T=641\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S100/S100R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 15743  =      0.000 ...   122.992 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 213 samples (1.664 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "24 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 24 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Skipping file ../data/full_data/S100/S100R12.edf because n_times=513 < target_T=641\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S100/S100R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 15743  =      0.000 ...   122.992 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 213 samples (1.664 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "24 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 24 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Skipping file ../data/full_data/S100/S100R04.edf because n_times=513 < target_T=641\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S094/S094R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S094/S094R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_86456/769691618.py:5: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(file_path, preload=True)\n",
      "/tmp/ipykernel_86456/769691618.py:5: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(file_path, preload=True)\n",
      "/tmp/ipykernel_86456/769691618.py:5: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S094/S094R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S029/S029R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19839  =      0.000 ...   123.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S029/S029R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19839  =      0.000 ...   123.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S029/S029R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19839  =      0.000 ...   123.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S040/S040R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S040/S040R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S040/S040R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S065/S065R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S065/S065R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from /home/niklas/Dokumente/AdvML/aml/EEG_MotorImagery_Project/data/full_data/S065/S065R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 641 original time points ...\n",
      "0 bad epochs dropped\n",
      "Final shape: (403, 64, 641) (403,)\n",
      "Skipped 3 files\n"
     ]
    }
   ],
   "source": [
    "for f in all_files:\n",
    "    X, y = process_file(f, T=4, n_channels=64, ds=1)\n",
    "    \n",
    "    n_times = X.shape[-1]\n",
    "    if target_T is None:\n",
    "        target_T = n_times\n",
    "        print(f\"Set target_T = {target_T} from file {f}\")\n",
    "    else:\n",
    "        if n_times > target_T:\n",
    "            X = X[..., :target_T]\n",
    "        elif n_times < target_T:\n",
    "            skipped_files += 1\n",
    "            print(f\"Skipping file {f} because n_times={n_times} < target_T={target_T}\")\n",
    "            continue\n",
    "    X_list.append(X)\n",
    "    y_list.append(y)\n",
    "X_all = np.concatenate(X_list, axis=0)\n",
    "y_all = np.concatenate(y_list, axis=0)\n",
    "\n",
    "print(\"Final shape:\", X_all.shape, y_all.shape)\n",
    "print(f\"Skipped {skipped_files} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ac49e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Subject: 1 File 0: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 1 File 1: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 1 File 2: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 2 File 3: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 2 File 4: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 2 File 5: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 3 File 6: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 3 File 7: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 3 File 8: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 4 File 9: X shape: (14, 64, 641), y shape: (14,)\n",
      " Subject: 4 File 10: X shape: (14, 64, 641), y shape: (14,)\n",
      " Subject: 4 File 11: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 5 File 12: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 5 File 13: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 5 File 14: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 6 File 15: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 6 File 16: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 6 File 17: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 7 File 18: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 7 File 19: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 7 File 20: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 8 File 21: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 8 File 22: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 8 File 23: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 9 File 24: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 9 File 25: X shape: (15, 64, 641), y shape: (15,)\n",
      " Subject: 9 File 26: X shape: (15, 64, 641), y shape: (15,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_list)):\n",
    "\n",
    "    print(f\" Subject: {(i//3)+1} File {i}: X shape: {X_list[i].shape}, y shape: {y_list[i].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f444ade2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([403, 1, 64, 641])\n"
     ]
    }
   ],
   "source": [
    "X_tensor = torch.tensor(X_all, dtype=torch.float32).unsqueeze(1)  # (trials, 1, C, T)\n",
    "y_tensor = torch.tensor(y_all, dtype=torch.long)\n",
    "\n",
    "print(X_tensor.shape)  # should be (N, 1, 64, 640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b423c64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "        \n",
    "def load_data(data_dir=\"./data/full_data\"):    \n",
    "    num_samples = X_tensor.shape[0]\n",
    "    indices = torch.randperm(num_samples)\n",
    "\n",
    "    train_end = int(0.7*num_samples)\n",
    "    val_end   = int(0.85*num_samples)\n",
    "\n",
    "    train_idx = indices[:train_end]\n",
    "    val_idx   = indices[train_end:val_end]\n",
    "    test_idx  = indices[val_end:]\n",
    "\n",
    "    train_X, train_y = X_tensor[train_idx], y_tensor[train_idx]\n",
    "    val_X, val_y     = X_tensor[val_idx], y_tensor[val_idx]\n",
    "    test_X, test_y   = X_tensor[test_idx], y_tensor[test_idx]\n",
    "\n",
    "\n",
    "    train_dataset = EEGDataset(train_X, train_y)\n",
    "    val_dataset   = EEGDataset(val_X, val_y)\n",
    "    test_dataset  = EEGDataset(test_X, test_y)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size= 16, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86155a3-2693-4383-8e9f-9c53a837c4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50332eb8-79fa-45a2-a20a-94685d4b741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_EEGNet(config): #, data_dir=None):\n",
    "    net = EEGNet(in_chans=64, n_classes=2, input_time=X_tensor.shape[-1], dropout = config[\"dropout\"]).to(device)\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    checkpoint = get_checkpoint()\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as checkpoint_dir:\n",
    "            data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "            with open(data_path, \"rb\") as fp:\n",
    "                checkpoint_state = pickle.load(fp)\n",
    "            start_epoch = checkpoint_state[\"epoch\"]\n",
    "            net.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    #trainset, testset = load_data(data_dir)\n",
    "    trainset = ray.get(config[\"traindata_ref\"])\n",
    "    testset = ray.get(config[\"testdata_ref\"])\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs]\n",
    "    )\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subset, batch_size=int(config[\"batch_size\"]), shuffle=True  #, num_workers=8\n",
    "    )\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_subset, batch_size=int(config[\"batch_size\"]), shuffle=True #, num_workers=8\n",
    "    )\n",
    "\n",
    "    for epoch in range(start_epoch, 10):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = EEGNet(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\n",
    "                    \"[%d, %5d] loss: %.3f\"\n",
    "                    % (epoch + 1, i + 1, running_loss / epoch_steps)\n",
    "                )\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = EEGNet(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        checkpoint_data = {\n",
    "            \"epoch\": epoch,\n",
    "            \"net_state_dict\": net.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }\n",
    "        with tempfile.TemporaryDirectory() as checkpoint_dir:\n",
    "            data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "            with open(data_path, \"wb\") as fp:\n",
    "                pickle.dump(checkpoint_data, fp)\n",
    "\n",
    "            checkpoint = Checkpoint.from_directory(checkpoint_dir)\n",
    "            train.report(\n",
    "                {\"loss\": val_loss / val_steps, \"accuracy\": correct / total},\n",
    "                checkpoint=checkpoint,\n",
    "            )\n",
    "\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d270885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.unique(train_y), np.unique(val_y))\n",
    "#print(np.count_nonzero(train_y), np.count_nonzero(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea3edf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "        0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27eafa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, in_chans=64, n_classes=2, input_time=640, dropout=0.5):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.firstconv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, (1, 64), padding=(0,32), bias=False),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "        self.depthwiseConv = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, (in_chans,1), groups=16, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d((1,4)),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.separableConv = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, (1,16), padding=(0,8), groups=32, bias=False),\n",
    "            nn.Conv2d(32, 32, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d((1,8)),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        # Compute flatten size dynamically\n",
    "        self.flatten_size = self._get_flatten_size(input_time)\n",
    "        self.classifier = nn.Linear(self.flatten_size, n_classes)\n",
    "        \n",
    "    def _get_flatten_size(self, input_time):\n",
    "        x = torch.zeros(1,1,64,input_time)\n",
    "        x = self.firstconv(x)\n",
    "        x = self.depthwiseConv(x)\n",
    "        x = self.separableConv(x)\n",
    "        return x.view(1,-1).shape[1]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.firstconv(x)\n",
    "        x = self.depthwiseConv(x)\n",
    "        x = self.separableConv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0db69fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = EEGNet(in_chans=64, n_classes=2, input_time=X_tensor.shape[-1], dropout = 0.5).to(device)  #config[\"dropout\"]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr =0.001 #lr=config[\"lr\"]\n",
    "                      )\n",
    "\n",
    "epochs = 0\n",
    "\n",
    "# ======== Initialize lists to store metrics ========\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ======== Training ========\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "    \n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    \n",
    "    # ======== Validation ========\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            val_correct += (preds == y_batch).sum().item()\n",
    "            val_total += y_batch.size(0)\n",
    "    \n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "          f\"Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n",
    "          f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd4ef313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 22:58:10,145\tINFO worker.py:2014 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "/home/niklas/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "2025-12-08 22:58:13,937\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Tracked actor is not managed by this event manager: <TrackedActor 122017383120271051960321317124942523047>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/tune/tune.py:994\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runner.is_finished() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event.is_set():\n\u001b[32m--> \u001b[39m\u001b[32m994\u001b[39m     \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    995\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_verbosity(Verbosity.V1_EXPERIMENT):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/tune/execution/tune_controller.py:685\u001b[39m, in \u001b[36mTuneController.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    684\u001b[39m \u001b[38;5;66;03m# Handle one event\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_actor_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m    686\u001b[39m     \u001b[38;5;66;03m# If there are no actors running, warn about potentially\u001b[39;00m\n\u001b[32m    687\u001b[39m     \u001b[38;5;66;03m# insufficient resources\u001b[39;00m\n\u001b[32m    688\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._actor_manager.num_live_actors:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/air/execution/_internal/actor_manager.py:190\u001b[39m, in \u001b[36mRayActorManager.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# We always try to start actors as this won't trigger an event callback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_start_actors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# If an actor was killed, this was our event, and we return.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/air/execution/_internal/actor_manager.py:360\u001b[39m, in \u001b[36mRayActorManager._try_start_actors\u001b[39m\u001b[34m(self, max_actors)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;66;03m# Start Ray actor\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m actor = \u001b[43mremote_actor_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# Track\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/actor.py:1478\u001b[39m, in \u001b[36mActorClass.options.<locals>.ActorOptionWrapper.remote\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1477\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mremote\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1478\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mactor_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_remote\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mupdated_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/_private/auto_init_hook.py:22\u001b[39m, in \u001b[36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     21\u001b[39m auto_init_ray()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/util/tracing/tracing_helper.py:384\u001b[39m, in \u001b[36m_tracing_actor_creation.<locals>._invocation_actor_class_remote_span\u001b[39m\u001b[34m(self, args, kwargs, *_args, **_kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_ray_trace_ctx\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m class_name = \u001b[38;5;28mself\u001b[39m.__ray_metadata__.class_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/actor.py:1646\u001b[39m, in \u001b[36mActorClass._remote\u001b[39m\u001b[34m(self, args, kwargs, **actor_options)\u001b[39m\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m meta.is_cross_language \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m   1636\u001b[39m     meta.last_export_cluster_and_job != worker.current_cluster_and_job\n\u001b[32m   1637\u001b[39m ):\n\u001b[32m   (...)\u001b[39m\u001b[32m   1644\u001b[39m     \u001b[38;5;66;03m# So, here pass actor_creation_function_descriptor to make\u001b[39;00m\n\u001b[32m   1645\u001b[39m     \u001b[38;5;66;03m# sure export actor class correct.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1646\u001b[39m     \u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunction_actor_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport_actor_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodified_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactor_creation_function_descriptor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod_meta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethods\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1651\u001b[39m     meta.last_export_cluster_and_job = worker.current_cluster_and_job\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/_private/function_manager.py:501\u001b[39m, in \u001b[36mFunctionActorManager.export_actor_class\u001b[39m\u001b[34m(self, Class, actor_creation_function_descriptor, actor_method_names)\u001b[39m\n\u001b[32m    492\u001b[39m actor_class_info = {\n\u001b[32m    493\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclass_name\u001b[39m\u001b[33m\"\u001b[39m: actor_creation_function_descriptor.class_name.split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m],\n\u001b[32m    494\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodule\u001b[39m\u001b[33m\"\u001b[39m: actor_creation_function_descriptor.module_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    498\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mactor_method_names\u001b[39m\u001b[33m\"\u001b[39m: json.dumps(\u001b[38;5;28mlist\u001b[39m(actor_method_names)),\n\u001b[32m    499\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m \u001b[43mcheck_oversized_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactor_class_info\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclass\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactor_class_info\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclass_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mactor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m._worker.gcs_client.internal_kv_put(\n\u001b[32m    509\u001b[39m     key, pickle.dumps(actor_class_info), \u001b[38;5;28;01mTrue\u001b[39;00m, KV_NAMESPACE_FUNCTION_TABLE\n\u001b[32m    510\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/_private/utils.py:637\u001b[39m, in \u001b[36mcheck_oversized_function\u001b[39m\u001b[34m(pickled, name, obj_type, worker)\u001b[39m\n\u001b[32m    626\u001b[39m error = (\n\u001b[32m    627\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m is too large (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m MiB > FUNCTION_SIZE_ERROR_THRESHOLD=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    628\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m MiB). Check that its definition is not implicitly capturing a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    635\u001b[39m     ray_constants.FUNCTION_SIZE_ERROR_THRESHOLD // (\u001b[32m1024\u001b[39m * \u001b[32m1024\u001b[39m),\n\u001b[32m    636\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error)\n",
      "\u001b[31mValueError\u001b[39m: The actor ImplicitFunc is too large (126 MiB > FUNCTION_SIZE_ERROR_THRESHOLD=95 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest trial test set accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(test_acc))\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# You can change the number of GPUs per trial here:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus_per_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(num_samples, max_num_epochs, gpus_per_trial)\u001b[39m\n\u001b[32m     11\u001b[39m config = {\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m\"\u001b[39m: tune.choice([\u001b[32m0.5\u001b[39m, \u001b[32m0.6\u001b[39m, \u001b[32m0.7\u001b[39m, \u001b[32m0.75\u001b[39m, \u001b[32m0.8\u001b[39m, \u001b[32m0.9\u001b[39m]),\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: tune.loguniform(\u001b[32m1e-3\u001b[39m, \u001b[32m1e-1\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtestdata_ref\u001b[39m\u001b[33m\"\u001b[39m: test_data_ref\n\u001b[32m     17\u001b[39m }\n\u001b[32m     19\u001b[39m scheduler = ASHAScheduler(\n\u001b[32m     20\u001b[39m     metric=\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     reduction_factor=\u001b[32m2\u001b[39m,\n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m result = \u001b[43mtune\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_EEGNet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#, data_dir=data_dir),\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresources_per_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus_per_trial\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m best_trial = result.get_best_trial(\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlast\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest trial config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_trial.config\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/tune/tune.py:1001\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[39m\n\u001b[32m    999\u001b[39m             _report_air_progress(runner, air_progress_reporter)\n\u001b[32m   1000\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m     \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1002\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1004\u001b[39m tune_taken = time.time() - tune_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/tune/execution/tune_controller.py:1978\u001b[39m, in \u001b[36mTuneController.cleanup\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1976\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcleanup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1977\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Cleanup trials and callbacks.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1978\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cleanup_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1979\u001b[39m     \u001b[38;5;28mself\u001b[39m.end_experiment_callbacks()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/tune/execution/tune_controller.py:792\u001b[39m, in \u001b[36mTuneController._cleanup_trials\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m     trial = \u001b[38;5;28mself\u001b[39m._actor_to_trial[tracked_actor]\n\u001b[32m    788\u001b[39m     logger.debug(\n\u001b[32m    789\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScheduling trial stop at end of experiment (trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    790\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtracked_actor\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    791\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_schedule_trial_stop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[38;5;66;03m# Clean up cached actors now\u001b[39;00m\n\u001b[32m    795\u001b[39m \u001b[38;5;28mself\u001b[39m._cleanup_cached_actors(force_all=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/tune/execution/tune_controller.py:1403\u001b[39m, in \u001b[36mTuneController._schedule_trial_stop\u001b[39m\u001b[34m(self, trial, exception)\u001b[39m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28mself\u001b[39m._actor_to_trial.pop(tracked_actor)\n\u001b[32m   1401\u001b[39m trial.set_ray_actor(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1403\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_remove_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracked_actor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracked_actor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/tune/execution/tune_controller.py:811\u001b[39m, in \u001b[36mTuneController._remove_actor\u001b[39m\u001b[34m(self, tracked_actor)\u001b[39m\n\u001b[32m    810\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_remove_actor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tracked_actor: TrackedActor):\n\u001b[32m--> \u001b[39m\u001b[32m811\u001b[39m     stop_future = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_actor_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mschedule_actor_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtracked_actor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_future\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    813\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    814\u001b[39m     now = time.monotonic()\n\u001b[32m    816\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._actor_manager.remove_actor(\n\u001b[32m    817\u001b[39m         tracked_actor, kill=\u001b[38;5;28;01mFalse\u001b[39;00m, stop_future=stop_future\n\u001b[32m    818\u001b[39m     ):\n\u001b[32m    819\u001b[39m         \u001b[38;5;66;03m# If the actor was previously alive, track\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dokumente/AdvML/aml/.aml_tut/lib/python3.12/site-packages/ray/air/execution/_internal/actor_manager.py:726\u001b[39m, in \u001b[36mRayActorManager.schedule_actor_task\u001b[39m\u001b[34m(self, tracked_actor, method_name, args, kwargs, on_result, on_error, _return_future)\u001b[39m\n\u001b[32m    723\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracked_actor \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._live_actors_to_ray_actors_resources:\n\u001b[32m    724\u001b[39m     \u001b[38;5;66;03m# Actor is not started, yet\u001b[39;00m\n\u001b[32m    725\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tracked_actor \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pending_actors_to_attrs:\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    727\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTracked actor is not managed by this event manager: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    728\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtracked_actor\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    729\u001b[39m         )\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# Cache tasks for future execution\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._pending_actors_to_enqueued_actor_tasks[tracked_actor].append(\n\u001b[32m    733\u001b[39m         (tracked_actor_task, method_name, args, kwargs)\n\u001b[32m    734\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Tracked actor is not managed by this event manager: <TrackedActor 122017383120271051960321317124942523047>"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=1):\n",
    "    ray.init()\n",
    "    data_dir = os.path.abspath(\"./data/full_data\")\n",
    "    traindata, testdata = load_data(data_dir)\n",
    "    train_data_ref = ray.put(traindata)\n",
    "    test_data_ref = ray.put(testdata)\n",
    "    \n",
    "\n",
    "    config = {\n",
    "        \"dropout\": tune.choice([0.5, 0.6, 0.7, 0.75, 0.8, 0.9]),\n",
    "        \"lr\": tune.loguniform(1e-3, 1e-1),\n",
    "        \"batch_size\": tune.choice([\"2\", \"4\", \"8\", \"16\",\"32\",\"64\"]),\n",
    "        \"traindata_ref\": train_data_ref,\n",
    "        \"testdata_ref\": test_data_ref\n",
    "    }\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "    result = tune.run(\n",
    "        partial(train_EEGNet),#, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 8, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "    )\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(f\"Best trial config: {best_trial.config}\")\n",
    "    print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "    print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n",
    "\n",
    "    best_trained_model = EEGNet(best_trial.config[\"dropout\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint = result.get_best_checkpoint(trial=best_trial, metric=\"accuracy\", mode=\"max\")\n",
    "    with best_checkpoint.as_directory() as checkpoint_dir:\n",
    "        data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "        with open(data_path, \"rb\") as fp:\n",
    "            best_checkpoint_data = pickle.load(fp)\n",
    "\n",
    "        best_trained_model.load_state_dict(best_checkpoint_data[\"net_state_dict\"])\n",
    "        test_acc = test_accuracy(best_trained_model, device)\n",
    "        print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    main(num_samples=10, max_num_epochs=10, gpus_per_trial=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ======== Loss Curve ========\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ======== Accuracy Curve ========\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4c1ef5-ce36-49f8-8d4c-d43278794f5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T16:44:34.940572Z",
     "start_time": "2025-12-06T16:44:34.903570Z"
    }
   },
   "outputs": [],
   "source": [
    "class Square(nn.Module):\n",
    "    \"\"\"x -> x^2\"\"\"\n",
    "    def forward(self, x):\n",
    "        return x ** 2\n",
    "\n",
    "class SafeLog(nn.Module):\n",
    "    \"\"\"x -> log(x) with numerical stabilisation\"\"\"\n",
    "    def __init__(self, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.log(torch.clamp(x, min=self.eps))\n",
    "\n",
    "# Shallow ConvNet Model\n",
    "class ShallowConvNet(nn.Module):\n",
    "    def __init__(self, n_classes: int, n_channels: int = 64, input_time_samples: int = 640, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_classes : int\n",
    "            Number of output classes.\n",
    "        n_channels : int\n",
    "            Number of electrodes\n",
    "        input_time_samples : int\n",
    "            Number of input time samples (e.g. 640 for 4 s @ 160 Hz).\n",
    "        \"\"\"\n",
    "        super(ShallowConvNet, self).__init__()\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.n_filters = 40\n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "        # Layers\n",
    "        # Input time x electrodes (paper 534x44, we _x64)\n",
    "        self.temporal_conv = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=self.n_filters,\n",
    "            kernel_size=(1, 16), # paper used 25 for sample rate 250 -> we use 16 for sample rate 160?\n",
    "            bias=False\n",
    "        ) # 40 Units temporal conv\n",
    "        \n",
    "        self.spatial_filter = nn.Conv2d(\n",
    "            in_channels=self.n_filters,\n",
    "            out_channels=self.n_filters,\n",
    "            kernel_size=(self.n_channels, 1),\n",
    "            groups=self.n_filters,\n",
    "            bias=False # arl disables bias\n",
    "        ) # 40 Units spatial filter (conv)\n",
    "        \n",
    "        self.bn = nn.BatchNorm2d(self.n_filters)\n",
    "        \n",
    "        self.square = Square() # Squaring Non-linearity\n",
    "        self.mean_pooling = nn.AvgPool2d(kernel_size=(1, 48), stride=(1, 9)) # 75x1 kernel Mean Pooling w. 15 x 1 stride -> 48, 1 and 9, 1 (or 10, 1?). Only AvgPooling available.\n",
    "        self.log_activation = SafeLog() # Log activation\n",
    "        \n",
    "        # Arl adds dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        n_features = self._get_flatten_size(input_time_samples)\n",
    "        self.dense = nn.Linear(n_features, n_classes) # Linear classification\n",
    "        #self.softmax = nn.Softmax(dim=1) # softmax\n",
    "\n",
    "    def _get_flatten_size(self, input_time):\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, 1, self.n_channels, input_time)\n",
    "            x = self.temporal_conv(x)\n",
    "            x = self.spatial_filter(x)\n",
    "            x = self.mean_pooling(x)\n",
    "            return x.flatten().shape[0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.temporal_conv(x)\n",
    "        out = self.spatial_filter(out)\n",
    "        out = self.bn(out)\n",
    "        out = self.square(out)\n",
    "        out = self.mean_pooling(out)\n",
    "        out = self.log_activation(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dense(out)\n",
    "        #out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cdced0-a58c-4f9c-b613-6a961fd41fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T16:44:37.039369Z",
     "start_time": "2025-12-06T16:44:37.035608Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb47334-bb9a-49cb-8060-8e59e26d503e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T17:00:59.952435Z",
     "start_time": "2025-12-06T16:44:38.533369Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ShallowConvNet(n_channels=64, n_classes=2, input_time_samples=X_tensor.shape[-1]).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 0\n",
    "\n",
    "# ======== Initialize lists to store metrics ========\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ======== Training ========\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "    \n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    \n",
    "    # ======== Validation ========\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            val_correct += (preds == y_batch).sum().item()\n",
    "            val_total += y_batch.size(0)\n",
    "    \n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "          f\"Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n",
    "          f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ab0e7-baeb-4243-aae8-03f729294497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T17:13:13.220177Z",
     "start_time": "2025-12-06T17:13:07.476934Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ======== Loss Curve ========\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ======== Accuracy Curve ========\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
